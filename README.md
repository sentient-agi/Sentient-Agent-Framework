<!-- Sentient Banner -->
<p align="center">
  <img src="banner.png"/>
</p>

<!-- Socials -->
<p align="center">
      <a href="https://sentient.xyz/" target="_blank" style="margin: 2px;">
    <img alt="Homepage" src="https://img.shields.io/badge/Website-Sentient.xyz-%23EAEAEA?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzNDEuMzMzIiBoZWlnaHQ9IjM0MS4zMzMiIHZlcnNpb249IjEuMCIgdmlld0JveD0iMCAwIDI1NiAyNTYiPjxwYXRoIGQ9Ik0xMzIuNSAyOC40Yy0xLjUgMi4yLTEuMiAzLjkgNC45IDI3LjIgMy41IDEzLjcgOC41IDMzIDExLjEgNDIuOSAyLjYgOS45IDUuMyAxOC42IDYgMTkuNCAzLjIgMy4zIDExLjctLjggMTMuMS02LjQuNS0xLjktMTcuMS03Mi0xOS43LTc4LjYtMS4yLTMtNy41LTYuOS0xMS4zLTYuOS0xLjYgMC0zLjEuOS00LjEgMi40ek0xMTAgMzBjLTEuMSAxLjEtMiAzLjEtMiA0LjVzLjkgMy40IDIgNC41IDMuMSAyIDQuNSAyIDMuNC0uOSA0LjUtMiAyLTMuMSAyLTQuNS0uOS0zLjQtMi00LjUtMy4xLTItNC41LTItMy40LjktNC41IDJ6TTgxLjUgNDYuMWMtMi4yIDEuMi00LjYgMi44LTUuMiAzLjctMS44IDIuMy0xLjYgNS42LjUgNy40IDEuMyAxLjIgMzIuMSAxMC4yIDQ1LjQgMTMuMyAzIC44IDYuOC0yLjIgNi44LTUuMyAwLTMuNi0yLjItOS4yLTMuOS0xMC4xQzEyMy41IDU0LjIgODcuMiA0NCA4NiA0NGMtLjMuMS0yLjMgMS00LjUgMi4xek0xNjUgNDZjLTEuMSAxLjEtMiAyLjUtMiAzLjIgMCAyLjggMTEuMyA0NC41IDEyLjYgNDYuNS45IDEuNSAyLjQgMi4zIDQuMiAyLjMgMy44IDAgOS4yLTUuNiA5LjItOS40IDAtMS41LTIuMS0xMC45LTQuNy0yMC44bC00LjctMTguMS00LjUtMi44Yy01LjMtMy40LTcuNC0zLjYtMTAuMS0uOXpNNDguNyA2NS4xYy03LjcgNC4xLTYuOSAxMC43IDEuNSAxMyAyLjQuNiAyMS40IDUuOCA0Mi4yIDExLjYgMjIuOCA2LjIgMzguOSAxMC4yIDQwLjMgOS44IDMuNS0uOCA0LjYtMy44IDMuMi04LjgtMS41LTUuNy0yLjMtNi41LTguMy04LjJDOTQuMiA3My4xIDU2LjYgNjMgNTQuOCA2M2MtMS4zLjEtNCAxLTYuMSAyLjF6TTE5OC4yIDY0LjdjLTMuMSAyLjgtMy41IDUuNi0xLjEgOC42IDQgNS4xIDEwLjkgMi41IDEwLjktNC4xIDAtNS4zLTUuOC03LjktOS44LTQuNXpNMTgxLjggMTEzLjFjLTI3IDI2LjQtMzEuOCAzMS41LTMxLjggMzMuOSAwIDEuNi43IDMuNSAxLjUgNC40IDEuNyAxLjcgNy4xIDMgMTAuMiAyLjQgMi4xLS4zIDU2LjktNTMuNCA1OS01Ny4xIDEuNy0zLjEgMS42LTkuOC0uMy0xMi41LTMuNi01LjEtNC45LTQuMi0zOC42IDI4Ljl6TTM2LjYgODguMWMtNSA0LTIuNCAxMC45IDQuMiAxMC45IDMuMyAwIDYuMi0yLjkgNi4yLTYuMyAwLTIuMS00LjMtNi43LTYuMy02LjctLjggMC0yLjYuOS00LjEgMi4xek02My40IDk0LjVjLTEuNi43LTguOSA3LjMtMTYuMSAxNC43TDM0IDEyMi43djUuNmMwIDYuMyAxLjYgOC43IDUuOSA4LjcgMi4xIDAgNi0zLjQgMTkuOS0xNy4zIDkuNS05LjUgMTcuMi0xOCAxNy4yLTE4LjkgMC00LjctOC40LTguNi0xMy42LTYuM3pNNjIuOSAxMzAuNiAzNCAxNTkuNXY1LjZjMCA2LjIgMS44IDguOSA2IDguOSAzLjIgMCA2Ni02Mi40IDY2LTY1LjYgMC0zLjMtMy41LTUuNi05LjEtNi4ybC01LS41LTI5IDI4Ljl6TTE5Ni4zIDEzNS4yYy05IDktMTYuNiAxNy4zLTE2LjkgMTguNS0xLjMgNS4xIDIuNiA4LjMgMTAgOC4zIDIuOCAwIDUuMi0yIDE3LjktMTQuOCAxNC41LTE0LjcgMTQuNy0xNC45IDE0LjctMTkuMyAwLTUuOC0yLjItOC45LTYuMi04LjktMi42IDAtNS40IDIuMy0xOS41IDE2LjJ6TTk2IDEzNi44Yy0yLjkuOS04IDYuNi04IDkgMCAxLjMgMi45IDEzLjQgNi40IDI3IDMuNiAxMy42IDcuOSAzMC4zIDkuNyAzNy4yIDEuNyA2LjkgMy42IDEzLjMgNC4xIDE0LjIuNSAxIDIuNiAyLjcgNC44IDMuOCA2LjggMy41IDExIDIuMyAxMS0zLjIgMC0zLTIwLjYtODMuMS0yMi4xLTg1LjktLjktMS45LTMuNi0yLjgtNS45LTIuMXpNMTIwLjUgMTU4LjRjLTEuOSAyLjktMS4yIDguNSAxLjQgMTEuNiAxLjEgMS40IDEyLjEgNC45IDM5LjYgMTIuNSAyMC45IDUuOCAzOC44IDEwLjUgMzkuOCAxMC41czMuNi0xIDUuNy0yLjJjOC4xLTQuNyA3LjEtMTAuNi0yLjMtMTMuMi0yOC4yLTguMS03OC41LTIxLjYtODAuMy0yMS42LTEuNCAwLTMgMS0zLjkgMi40ek0yMTAuNyAxNTguOGMtMS44IDEuOS0yLjIgNS45LS45IDcuOCAxLjUgMi4zIDUgMy40IDcuNiAyLjQgNi40LTIuNCA1LjMtMTEuMi0xLjUtMTEuOC0yLjQtLjItNCAuMy01LjIgMS42ek02OS42IDE2MmMtMiAyLjItMy42IDQuMy0zLjYgNC44LjEgMi42IDEwLjEgMzguNiAxMS4xIDM5LjkgMi4yIDIuNiA5IDUuNSAxMS41IDQuOSA1LTEuMyA0LjktMy0xLjUtMjcuNy0zLjMtMTIuNy02LjUtMjMuNy03LjItMjQuNS0yLjItMi43LTYuNC0xLjctMTAuMyAyLjZ6TTQ5LjYgMTgxLjVjLTIuNCAyLjUtMi45IDUuNC0xLjIgOEM1MiAxOTUgNjAgMTkzIDYwIDE4Ni42YzAtMS45LS44LTQtMS44LTQuOS0yLjMtMi4xLTYuNi0yLjItOC42LS4yek0xMjguNSAxODdjLTIuMyAyLjUtMS4zIDEwLjMgMS42IDEyLjggMi4yIDEuOSAzNC44IDExLjIgMzkuNCAxMS4yIDMuNiAwIDEwLjEtNC4xIDExLTcgLjYtMS45LTEuNy03LTMuMS03LS4yIDAtMTAuMy0yLjctMjIuMy02cy0yMi41LTYtMjMuMy02Yy0uOCAwLTIuMy45LTMuMyAyek0xMzYuNyAyMTYuOGMtMy40IDMuOC0xLjUgOS41IDMuNSAxMC43IDMuOSAxIDguMy0zLjQgNy4zLTcuMy0xLjItNS4xLTcuNS03LjEtMTAuOC0zLjR6Ii8%2BPC9zdmc%2B&link=https%3A%2F%2Fhuggingface.co%2FSentientagi"/>
  </a>
    <!-- Twitter -->
    <a href="https://x.com/SentientAGI">
        <img alt="Twitter Follow" src="https://img.shields.io/badge/Twitter-SentientAGI-white?logo=x"/>
    </a>
    <!-- Discord -->
    <a href="https://discord.gg/sentientfoundation">
        <img alt="Discord" src="https://img.shields.io/badge/Discord-SentientAGI-7289da?logo=discord&logoColor=white&color=7289da"/>
    </a>
    <!-- Hugging face -->
    <a href="https://huggingface.co/Sentientagi">
        <img src="https://img.shields.io/badge/Hugging_Face-SentientAGI-yellow?style=sociak&logo=huggingface"/>
    </a>
</p>

<!-- Github Repo Info -->
<p align="center">
    <!-- Release -->
    <a href="https://github.com/sentient-agi/Sentient-Agent-Framework/releases">
        <img alt="GitHub release" src="https://img.shields.io/badge/Release-Beta-yellow">
    </a>
    <!-- License -->
    <a href="https://github.com/sentient-agi/Sentient-Agent-Framework/tree/main?tab=Apache-2.0-1-ov-file">
        <img alt="License" src="https://img.shields.io/badge/License-Apache_2.0-green">
    </a>
</p>


<h1 align="center">Sentient Agent Framework</h1>

> [!WARNING]
> **This python package is currently in beta and will likely change. It is not yet ready for production use.**

In addition to supporting OpenAI API compatible agents, Sentient Chat supports a custom, open source event system for agent responses. These events can be rendered in Sentient Chat to provide a richer user experience. This particularly useful for streaming responses from an AI agent, when you might want to show the agent's work while the response is being generated, rather than having the user wait for the final response. **This python package provides an agent framework that can be used to build agents that serve Sentient Chat events.**

Examples of agents that use this framework/package can be found [here](https://github.com/sentient-agi/Sentient-Agent-Framework-Examples).

# Usage
The simplest ways to use this framework are to either import and use the `DefaultAgent` class or the `DefaultResponseHandler` class.

| DefaultAgent | DefaultResponseHandler |
|---------------------|--------------------------------|
| Provides SSE server with `/assist` endpoint | You manage your own server implementation |
| Emitted events are automatically streamed to client | Emitted events are added to a queue - you handle streaming events to client |
| Implement `assist()` method and emit events | Implement server that streams events from queue, use `DefaultResponseHandler` to add events to queue |
| Best for simple agent implementations | Better for custom server architectures |

## Installation
```bash
pip install sentient-agent-framework
```

## Using DefaultAgent
Subclass the `DefaultAgent` class and implement the `assist()` method. Use the `ResponseHandler` object passed to the `assist()` method to emit events to the client:

#### search_agent.py
```python
import logging
import os
from dotenv import load_dotenv
from src.search_agent.providers.model_provider import ModelProvider
from src.search_agent.providers.search_provider import SearchProvider
from sentient_agent_framework import (
    BaseAgent,
    Identity,
    Session,
    Query,
    ResponseHandler)
from typing import Iterator


load_dotenv()
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


class SearchAgent(BaseAgent):
    def __init__(
            self,
            identity: Identity
    ):
        super().__init__(identity)

        model_api_key = os.getenv("MODEL_API_KEY")
        if not model_api_key:
            raise ValueError("MODEL_API_KEY is not set")
        self._model_provider = ModelProvider(api_key=model_api_key)

        search_api_key = os.getenv("TAVILY_API_KEY")
        if not search_api_key:
            raise ValueError("TAVILY_API_KEY is not set") 
        self._search_provider = SearchProvider(api_key=search_api_key)


    async def assist(
            self,
            session: Session,
            query: Query,
            response_handler: ResponseHandler
    ):
        """Search the internet for information."""
        # Rephrase query for better search results
        await response_handler.emit_text_block(
            "PLAN", "Rephrasing user query..."
        )
        rephrased_query = self.__rephrase_query(query)
        await response_handler.emit_text_block(
            "REPHRASE", f"Rephrased query: {rephrased_query}"
        )

        # Search for information
        await response_handler.emit_text_block(
            "SEARCH", "Searching internet for results..."
        )
        search_results = self._search_provider.search(rephrased_query)
        if len(search_results["results"]) > 0:
            await response_handler.emit_json(
                "SOURCES", {"results": search_results["results"]}
            )
        if len(search_results["images"]) > 0:
            await response_handler.emit_json(
                "IMAGES", {"images": search_results["images"]}
            )

        # Process search results
        final_response_stream = response_handler.create_text_stream(
            "FINAL_RESPONSE"
            )
        for chunk in self.__process_search_results(search_results["results"]):
            await final_response_stream.emit_chunk(chunk)
        await final_response_stream.complete()
        await response_handler.complete()


    def __rephrase_query(
            self,
            query: str
    ) -> str:
        """Rephrase the query for better search results."""
        rephrase_query = f"Rephrase the following query for better search results: {query}"
        rephrase_query_response = self._model_provider.query(rephrase_query)
        return rephrase_query_response
    

    def __process_search_results(
            self, 
            search_results: dict
    ) -> Iterator[str]:
        """Process the search results."""
        process_search_results_query = f"Summarise the following search results: {search_results}"
        for chunk in self._model_provider.query_stream(process_search_results_query):
            yield chunk


if __name__ == "__main__":
    agent = SearchAgent(identity=Identity(id="Search-Demo", name="Search Demo"))
    agent.run_server()
```


## Using DefaultResponseHandler
#### search_agent.py
```python
import logging
import os
from dotenv import load_dotenv
from queue import Queue
from src.agent.providers.model_provider import ModelProvider
from src.agent.providers.search_provider import SearchProvider
from sentient_agent_framework import (
    DefaultResponseHandler,
    DefaultHook,
    Identity)
from typing import Iterator


load_dotenv()
logger = logging.getLogger(__name__)


class SearchAgent:
    def __init__(
            self,
            identity: Identity,
            response_queue: Queue
    ):
        self._identity = identity
        self._response_queue = response_queue

        model_api_key=os.getenv("MODEL_API_KEY")
        if not model_api_key:
            raise ValueError("MODEL_API_KEY is not set")
        self._model_provider = ModelProvider(api_key=model_api_key)

        search_api_key=os.getenv("TAVILY_API_KEY")
        if not search_api_key:
            raise ValueError("TAVILY_API_KEY is not set") 
        self._search_provider = SearchProvider(api_key=search_api_key)


    async def search(
            self,
            query: str
    ):
        response_handler = DefaultResponseHandler(self._identity, DefaultHook(self._response_queue))
        """Search the internet for information."""
        # Rephrase query for better search results
        await response_handler.emit_text_block(
            "PLAN", "Rephrasing user query..."
        )
        rephrased_query = self.__rephrase_query(query)
        await response_handler.emit_text_block(
            "REPHRASE", f"Rephrased query: {rephrased_query}"
        )

        # Search for information
        await response_handler.emit_text_block(
            "SEARCH", "Searching internet for results..."
        )
        search_results = self._search_provider.search(rephrased_query)
        if len(search_results["results"]) > 0:
            await response_handler.emit_json(
                "SOURCES", {"results": search_results["results"]}
            )
        if len(search_results["images"]) > 0:
            await response_handler.emit_json(
                "IMAGES", {"images": search_results["images"]}
            )

        # Process search results
        final_response_stream = response_handler.create_text_stream(
            "FINAL_RESPONSE"
            )
        for chunk in self.__process_search_results(search_results["results"]):
            await final_response_stream.emit_chunk(chunk)
        await final_response_stream.complete()
        await response_handler.complete()


    def __rephrase_query(
            self,
            query: str
    ) -> str:
        """Rephrase the query for better search results."""
        rephrase_query = f"Rephrase the following query for better search results: {query}"
        rephrase_query_response = self._model_provider.query(rephrase_query)
        return rephrase_query_response
    

    def __process_search_results(
            self, 
            search_results: dict
    ) -> Iterator[str]:
        """Process the search results."""
        process_search_results_query = f"Summarise the following search results: {search_results}"
        for chunk in self._model_provider.query_stream(process_search_results_query):
            yield chunk
```

#### flask_server.py
```python
import asyncio
import threading
from flask import Flask, Response, request
from queue import Queue
from src.search_agent.search_agent import SearchAgent
from sentient_agent_framework import Identity
from sentient_agent_framework.interface.events import DoneEvent


app = Flask(__name__)
response_queue=Queue()
agent = Agent(
    identity=Identity(id="SSE-Demo", name="SSE Demo"),
    response_queue=response_queue
)


def generate_data(query):
    threading.Thread(target=lambda: asyncio.run(agent.search(query))).start()
    while True:
        event = response_queue.get()
        yield f"data: {event}\n\n"
        if type(event) == DoneEvent:
            break
        


@app.route('/query')
def stream():
    query = request.get_json()["query"]
    return Response(generate_data(query), content_type='text/event-stream')


if __name__ == '__main__':
    app.run(debug=True)
```

## Emitting events
Whether using the `DefaultAgent` or the `DefaultResponseHandler`, a `ResponseHandler` is created for every agent query and is used to emit events to the client. 

#### Emitting text events
Text events are used to send single, complete messages to the client:
```python
await response_handler.emit_text_block(
    "PLAN", "Rephrasing user query..."
)
```

#### Emitting JSON events
JSON events are used to send JSON objects to the client:
```python
await response_handler.emit_json(
    "SOURCES", {"results": search_results["results"]}
)
```

#### Emitting error events
Error events are used to send error messages to the client:
```python
await response_handler.emit_error(
    "ERROR", {"message": "An error occurred"}
)
```

#### Completing a response
At the end of a response, `response_handler.complete()` is called to signal the end of the response (this will emit a `DoneEvent` using the `Hook`):
```python
await response_handler.complete()
```

#### Emitting a stream of text chunks
To stream a longer response one chunk at a time, use the `response_handler.create_text_stream` method. This returns a `StreamEventEmitter` that can be used to stream text to the client using the `emit_chunk` method:
```python
final_response_stream = response_handler.create_text_stream(
    "FINAL_RESPONSE"
    )
for chunk in self.__process_search_results(search_results["results"]):
    await final_response_stream.emit_chunk(chunk)
```

#### Completing a stream
At the end of the stream, `final_response_stream.complete()` is called to signal the end of the stream (this will emit a `TextChunkEvent` with `is_complete=True`):
```python
await final_response_stream.complete()
```

## Documentation
- [Interface Documentation](./src/sentient_agent_framework/interface/README.md)
- [Implementation Documentation](./src/sentient_agent_framework/implementation/README.md)